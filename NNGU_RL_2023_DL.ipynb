{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inffe/rl-unn/blob/main/NNGU_RL_2023_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5BUkgn_02gM",
        "outputId": "fd997bef-295a-495a-f964-b2ff39cb5e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 13:07:16--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813 [text/plain]\n",
            "Saving to: ‘tiny_img.py’\n",
            "\n",
            "\rtiny_img.py           0%[                    ]       0  --.-KB/s               \rtiny_img.py         100%[===================>]     813  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-07 13:07:16 (32.5 MB/s) - ‘tiny_img.py’ saved [813/813]\n",
            "\n",
            "--2023-04-07 13:07:16--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1555 (1.5K) [text/plain]\n",
            "Saving to: ‘tiny_img_dataset.py’\n",
            "\n",
            "tiny_img_dataset.py 100%[===================>]   1.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-07 13:07:17 (23.8 MB/s) - ‘tiny_img_dataset.py’ saved [1555/1555]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!S:bash\n",
        "# if you are in colab, just add '!' in the start of the following line\n",
        "!wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py' -O tiny_img.py\n",
        "!wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py' -O tiny_img_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "from tiny_img import download_tinyImg200\n",
        "data_path = '.'\n",
        "download_tinyImg200(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYpTRF5206t0",
        "outputId": "f7db5f37-b9b1-4ddd-de34-73c525fb4b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset was downloaded to './tiny-imagenet-200.zip'\n",
            "Extract downloaded dataset to '.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "\n",
        "def get_computing_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "device = get_computing_device()\n",
        "print(f\"Our main computing device is '{device}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNavi3J609OT",
        "outputId": "581113f5-8347-4f6a-eb7a-df7f367dccb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our main computing device is 'cpu'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_trainsforms = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "hX-fKu-T0_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "import tiny_img_dataset\n",
        "# you may use torchvision.datasets.ImageFolder() with the same parameters for loading train dataset \n",
        "train_dataset = tiny_img_dataset.TinyImagenetRAM('tiny-imagenet-200/train', transform=train_trainsforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWQ1SnUu1CIn",
        "outputId": "9deb0383-1003-400e-de18-8990a96cb1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/train: 100%|██████████| 200/200 [01:18<00:00,  2.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class TinyImagenetValDataset(Dataset):\n",
        "    def __init__(self, root, transform=transforms.ToTensor()):\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = root\n",
        "        with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
        "            annotations = []\n",
        "            for line in f:\n",
        "                img_name, class_label = line.split('\\t')[:2]\n",
        "                annotations.append((img_name, class_label))\n",
        "        self.classes = sorted(list(set(el[1] for el in annotations)))\n",
        "\n",
        "        \n",
        "        assert len(self.classes) == 200, len(self.classes)\n",
        "        assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n",
        "        assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n",
        "\n",
        "        self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images, self.targets = [], []\n",
        "        for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n",
        "            img_name = os.path.join(root, 'images', img_name)\n",
        "            image = tiny_img_dataset.read_rgb_image(img_name)\n",
        "            \n",
        "            assert image.shape == (64, 64, 3), image.shape\n",
        "            self.images.append(Image.fromarray(image))\n",
        "            self.targets.append(self.class_to_idx[class_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image = self.images[index]\n",
        "        image = self.transform(image)\n",
        "        target=self.targets[index]\n",
        "\n",
        "\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "mOyyCe1x1EPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
        "\n",
        "assert all(train_dataset.classes[i] == val_dataset.classes[i] for i in range(200)), \\\n",
        "    'class order in train and val datasets should be the same'\n",
        "assert all(train_dataset.class_to_idx[elem] == val_dataset.class_to_idx[elem] for elem in train_dataset.classes), \\\n",
        "    'class indices should be the same'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnHA5S361HYL",
        "outputId": "6d6ac713-c996-4f34-eb54-815d7b60bff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:08<00:00, 1154.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "batch_size = 64\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "metadata": {
        "id": "iz9R8ppb1Jtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=1)"
      ],
      "metadata": {
        "id": "wi-dxJs11MFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "dj1Rq45S1Ojd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        pass"
      ],
      "metadata": {
        "id": "LBHra6cc1Q8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyeoSxK31dTx",
        "outputId": "d2d60a22-b624-49c0-ae72-ca02cab5dcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleModel()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "def compute_loss(predictions, gt):\n",
        "    return F.cross_entropy(predictions, gt).mean()"
      ],
      "metadata": {
        "id": "2Ld5WmZk1f1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def eval_model(model, data_generator):\n",
        "    accuracy = []\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_generator:\n",
        "            X_batch = X_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
        "    return np.mean(accuracy)\n",
        "\n",
        "            \n",
        "def train_model(model, optimizer, train_data_generator):\n",
        "    train_loss = []\n",
        "    accuracy = []\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # YOUR CODE: move X_batch, y_batch to 'device', compute model outputs on X_batch, \n",
        "        # run `compute_loss()` function\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        predictions = model(X_batch)\n",
        "        loss = compute_loss(predictions,y_batch)\n",
        "        y_pred = predictions.max(1)[1].data\n",
        "        accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # metrics\n",
        "        # train_loss.append(loss.cpu().data.numpy())\n",
        "    return np.mean(accuracy)\n",
        "\n",
        "\n",
        "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs):\n",
        "    \"\"\"\n",
        "    num_epochs - total amount of full passes over training data\n",
        "    \"\"\"\n",
        "    total_train_acc = []\n",
        "    total_val_acc = []\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_accuracy = train_model(model, optimizer, train_data_generator)\n",
        "        total_train_acc.append(train_accuracy)\n",
        "        val_accuracy = eval_model(model, val_data_generator)\n",
        "        total_val_acc.append(val_accuracy)\n",
        "\n",
        "        # Then we print the results for this epoch:\n",
        "        clear_output()\n",
        "        plt.title('Accuracy')\n",
        "        plt.plot(total_train_acc, label='train')\n",
        "        plt.plot(total_val_acc, label='validation')\n",
        "        plt.xlabel('number of epoch')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    print(f'finally accuracy on train - {total_train_acc[-1]}, on validation - {total_val_acc[-1]}')"
      ],
      "metadata": {
        "id": "XPJFpGDm1l26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters())\n",
        "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
      ],
      "metadata": {
        "id": "Uadc5FjQ1vkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}